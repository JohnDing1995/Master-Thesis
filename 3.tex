\chapter{Overview of Current Serverless Cloud Services Offering in AWS}
In this chapter, I will introduce the serverless cloud services in Amazon Web Services (AWS) that I will use in the DevOps toolchain and the experiments.
 In 3.1, I introduce the AWS Elastic Container Services and AWS Fargate. In 3.2 I introduce the AWS Lambda and AWS CloudWatch in 3.3. I introduce AWS DevOps tools in 3.4.
\section{AWS Elastic Container Services with Fargate}
In our toolchain, I make use of Elastic Container Services with Fargate to run the Jenkins build agent. In this section, I introduce ECS and Fargate, and how do they combine to host the serverless Docker container.
\subsection{AWS Elastic Container Service(ECS)}
Amazon Elastic Container Service is a managed container orchestration service that runs Docker containers. AWS fully manages the ECS service, which means that AWS will be responsible for some operational tasks, such as automatically scaling the running container. In order to introduce how the container runs on ECS, I first introduce a few concepts.
\paragraph{Task:} Task means a container instance that runs in the ECS cluster. A task is defined by task definition, which is a JSON file that contains the following information: container definition, network, hardware configuration and launch type. The task is the instantiation of a task definition \cite{WhatisAm71:online}. The ECS task scheduler is responsible for putting the task to the cluster. 
\paragraph{Service:} A service is an abstraction of a set of tasks that include a specified number of tasks runs simultaneously.
\paragraph{Launch Type:} Launch type defines on which infrastructure the task will run. Currently, there are two options, EC2 (virtual machine) and Fargate (serverless). The EC2 launch type refers to running the container (task) in a group of EC2 virtual machines. This launch type requires the user to manually create and managing EC2 VMs. The Fargate launch type means run containers in AWS Fargate, and Fargate is a serverless container service in AWS. This launch type does not require user provisioning and managing the infrastructure that runs the containers. Instead, AWS takes over these tasks. Our first experiment in chapter 5 will be related to a comparison between these two launch types.
\par
The workflow for running an container in ECS is as follows:
The first step is to have the task definition define the specification of the Docker container that is going to run. In the next step, a task defined by this task definition is created.
\par
In the DevOps tool chain, ECS can be used to host Docker-based build agents in the continuous delivery pipeline. Docker-based build agent means running certain stages in the pipeline distributed in Docker containers. 
ECS supports the use of APIs to perform the two steps we mentioned in last paragraph, which makes it easy for DevOps tools to deploy Docker-based build agents to ECS cluster.
Major continuous delivery tools support the Docker-based build agent. 
I will thoroughly introduce the Docker-based build agent in 4.2.
\subsection{AWS Fargate}
AWS Fargate is a serverless container service by AWS, and as I mentioned above, one of the launch types of ECS. It removes the need for provision, manages the server from the user's side. Fargate also follows the payment mode of serverless computing, which is paid for the runtime of each running container. 
\par
I notice that different from other serverless computing services in AWS, for example, AWS Lambda, Fargate cannot be used independently. To use Fargate, the user needs to select it as "Launch type" in Elastic Container Service, which means the container runs under this task definition will run in Fargate.  I call this method of using Fargate as "Elastic Container with Fargate" in the following chapters. Another way of using Fargate is to run pods in Fargate when deploying Kubernetes cluster to AWS Elastic Kubernetes Service (EKS). This way user could run a fully serverless Kubernetes cluster in AWS, without managing backend infrastructure which runs each pod of the cluster.
\section{AWS Lambda}
AWS Lambda is AWSâ€™s first serverless service,
It was launched in November 2014. In AWS Lambda, users can upload codes called "Lambda functions" to AWS Lambda. AWS Lambda runs the code in its own hosting infrastructure. "Managed" refers to AWS performing all management tasks of back-end services, including server and OS maintenance, server configuration, and scaling. In addition to server-related tasks, AWS will also be responsible for security, monitoring, and logging.
\par
AWS Lambda is event-driven, which means that when an incoming event triggers the function, the deployed lambda function will start running. I introduced the characteristics and applications of even driving in 2.4.2. In addition, AWS allows user to associate Lambda functions with other AWS services. This means that changes in AWS services can be used to trigger our Lambda functions. The combination of even-numbered driving characteristics and association with AWS services allows user to extend the functionality of AWS services. I will introduce how to use this combination in Chapter 4.
\section{AWS CloudWatch}
As I mentioned in chapter 2, monitoring is one of the DevOps practises. AWS CloudWatch is a monitoring and observability service \cite{AmazonCl65:online}. It providing an out-of-box monitoring solution for both infrastructure and deployed applications. CloudWatch could also helps on resource utilization and gives an uniform platform to monitoring operational health of the infrastructure in both AWS and on-premises. In addition, CloudWatch gives a complete visibility to AWS infrastructure status, because CloudWatch natively integrates with over 70 AWS cloud services \cite{AmazonCl65:online}.
\par
The core function of CloudWatch is to collect metrics and logs of all running AWS services under the current user, display these data in real time and save the data for further analysis.
CloudWatch supports monitoring all services running in serverless and server-based AWS. In addition, it can be used to monitor on-premises services. Monitoring in CloudWatch follows the following workflow:
\begin{enumerate}
    \item \textbf{Collect:} CloudWatch gathers the log from services in AWS. In addition, it also gathers metrics include CPU/RAM utilization, network I/O e.g..
    \item \textbf{Monitor:} CloudWatch visualizes application and infrastructure logs and metrics on the dashboard. Users can check the status from the dashboard and can also set CloudWatch alarms.
    \item \textbf{Act:} CloudWatch continuously monitors the status of AWS services.
    When certain metrics reach the value set in the CloudWatch alarm, the alarm will trigger the action set by the user. A common use case is to set an alarm about CPU usage and use that alarm to trigger auto-scaling. Alarm actions may also trigger Lambda functions.
    \item \textbf{Analyze:} CloudWatch can save logs and analyze them later. The analysis includes customizable indicators, contributor insights and log analysis.
\end{enumerate}
I will introduce how the CloudWatch is being used in our toolchain in chapter 4.
\section{AWS Developer Tools}
AWS provides a set of cloud-based tools which helps user to build an integrated DevOps toolchain. These tools include the following four tools.
\subsection{CodeBuild}
CodeBuild is a fully managed build server in AWS. CodeBuild mainly takes care of the automated build and automated testing within configuration delivery. Same with all serverless services, CodeBuild frees the software team from building and managing build servers.
\par
Although as a managed service, still, CodeBuild provides the user with a configurable build environment. Users are allowed to select the hardware configuration of the build machine. CodeBuild provides several out-of-box build environments which include build dependencies for the project in different programming languages. For example, a Java environment including JDK and Gradle; PIP and Python for Python development; Android build environment, etc.\footnote{The full list can be found at https://docs.aws.amazon.com/codebuild/latest/userguide/build-env-ref-available.html} Users can also use a self-defined build environment in compilable with their requirement.
Furthermore, CodeBuild provides good integration with popular tools. For example, CodeBuild can be integrated into a continuous pipeline in Jenkins by acting as a Jenkins build agent. This could be achieved through Jenkins' plugin "AWS CodeBuild" \footnote{https://plugins.jenkins.io/aws-codebuild/} developed by AWS CodeBuild engineering team.
\subsection{CodeDeploy}
CodeDeploy is for automating the application deployment to both AWS services and on-premise services. 
Besides the basic functionality as automated deployment, CodeDeploy also minimized the downtime by using advanced deployment strategies (blue/green deployment and rolling update) and continuous health checking. 
CodeDeploy also allows users to continuously monitor the running status of deployed applications.
\subsection{CodePipeline}
CodePipeline is for modelling the workflow within the continuous delivery pipeline with both graphic interface and code. The user could use different DevOps tools from AWS or third party in each stage of the CodePipeline. In the other way around, CodePipeline could connect different DevOps tools I mentioned above into an integrated continuous delivery pipeline. These tools include AWS DevOps tools such as CodeCommit, CodeDeploy, CodeBuild; Third-party tools such as GitHub, Jenkins, XebiaLabs etc. \footnote{See https://aws.amazon.com/codepipeline/product-integrations/}
\subsection{CodeStar}
CodeStar is a uniform platform that joins AWS DevOps tools as an integrated DevOps toolchain. I mentioned CodePipeline above which integrated different tools to an integrated continuous delivery pipeline, while CodeStar brings the integration to a further step.
I will introduce what tools does CodeStar include in section \ref{codestar} where I present our implementation of integrated DevOps toolchain in AWS.